// Copyright (c) 2025 Michael Ivertowski, Ernst & Young Ltd. Switzerland
// Licensed under the Business Source License 1.1 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://github.com/mivertowski/UniversalCompute/blob/master/LICENSE.txt
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
// NOTICE: This software is NOT licensed for commercial or production use.
// Change Date: 2029-06-24
// Change License: Apache License, Version 2.0

using BenchmarkDotNet.Attributes;
using ILGPU.Runtime;
using ILGPU.Runtime.CPU;
using ILGPU.Apple.NeuralEngine;

namespace ILGPU.Benchmarks.Benchmarks;

/// <summary>
/// Benchmarks for Apple Neural Engine (ANE) operations.
/// ANE operations are simulated when actual Apple Neural Engine hardware is not available.
/// </summary>
[MemoryDiagnoser]
[SimpleJob]
public class AppleNeuralEngineBenchmarks : IDisposable
{
    private Context? context;
    private Accelerator? accelerator;
    private AppleNeuralEngineAccelerator? aneAccelerator;
    private bool hasRealANE;
    private MemoryBuffer2D<float, Stride2D.DenseX>? inputMatrix;
    private MemoryBuffer2D<float, Stride2D.DenseX>? weightMatrix;
    private MemoryBuffer2D<float, Stride2D.DenseX>? outputMatrix;
    private MemoryBuffer1D<float, Stride1D.Dense>? inputVector;
    private MemoryBuffer1D<float, Stride1D.Dense>? outputVector;

    [Params(128, 512, 1024, 2048)]
    public int MatrixSize { get; set; }

    [Params(16, 32, 64)]
    public int BatchSize { get; set; }

    [GlobalSetup]
    public void Setup()
    {
        try
        {
            context = Context.CreateDefault();
            
            // Check for real Apple Neural Engine hardware first
            hasRealANE = ANECapabilities.DetectNeuralEngine();
            
            if (hasRealANE)
            {
                Console.WriteLine("üöÄ Detected Apple Neural Engine - using real hardware acceleration!");
                try
                {
                    accelerator = context.CreateANEAccelerator(0);
                    aneAccelerator = accelerator as AppleNeuralEngineAccelerator;
                    if (aneAccelerator == null)
                    {
                        Console.WriteLine("‚ö†Ô∏è ANE hardware detected but accelerator creation failed, falling back to simulation");
                        hasRealANE = false;
                    }
                }
                catch (Exception ex)
                {
                    Console.WriteLine($"‚ö†Ô∏è ANE hardware detected but not accessible: {ex.Message}, falling back to simulation");
                    hasRealANE = false;
                }
            }
            else
            {
                Console.WriteLine("‚ÑπÔ∏è Apple Neural Engine not detected - using ILGPU simulation");
            }
            
            // Fallback to regular ILGPU accelerator if ANE not available
            if (!hasRealANE)
            {
                var device = context.GetPreferredDevice(preferCPU: false) ?? 
                            context.GetPreferredDevice(preferCPU: true);
                accelerator = device.CreateAccelerator(context);
            }

            // Allocate memory for neural engine operations
            inputMatrix = accelerator.Allocate2DDenseX<float>(new Index2D(MatrixSize, MatrixSize));
            weightMatrix = accelerator.Allocate2DDenseX<float>(new Index2D(MatrixSize, MatrixSize));
            outputMatrix = accelerator.Allocate2DDenseX<float>(new Index2D(MatrixSize, MatrixSize));
            
            inputVector = accelerator.Allocate1D<float>(MatrixSize * BatchSize);
            outputVector = accelerator.Allocate1D<float>(MatrixSize * BatchSize);

            InitializeTestData();
            
            // Print ANE capabilities if available
            if (hasRealANE)
            {
                var caps = ANECapabilities.Query();
                Console.WriteLine($"üíª ANE Generation: {caps.Generation}");
                Console.WriteLine($"üîß Max TOPS: {caps.MaxTOPS:F1}, Core ML Support: {caps.SupportsCoreML}");
                Console.WriteLine($"üì° Float16 Support: {caps.SupportsFloat16}, Transformer Support: {caps.SupportsTransformer}");
            }
        }
        catch (Exception ex)
        {
            throw new NotSupportedException($"Failed to initialize ANE benchmark environment: {ex.Message}", ex);
        }
    }

    private void InitializeTestData()
    {
        var random = new Random(42);
        var totalElements = MatrixSize * MatrixSize;
        
        // Initialize matrices with Gaussian distribution (typical for neural networks)
        var inputData = new float[totalElements];
        var weightData = new float[totalElements];
        
        for (int i = 0; i < totalElements; i++)
        {
            inputData[i] = (float)NextGaussian(random, 0, 1);
            weightData[i] = (float)NextGaussian(random, 0, 0.1); // Xavier initialization
        }
        
        // Initialize vector data
        var vectorData = new float[MatrixSize * BatchSize];
        for (int i = 0; i < vectorData.Length; i++)
        {
            vectorData[i] = (float)NextGaussian(random, 0, 1);
        }
        
        if (inputMatrix != null)
        {
            var index = 0;
            for (int y = 0; y < inputMatrix.IntExtent.Y && index < inputData.Length; y++)
            {
                for (int x = 0; x < inputMatrix.IntExtent.X && index < inputData.Length; x++)
                {
                    inputMatrix.View[y, x] = inputData[index++];
                }
            }
        }
        if (weightMatrix != null)
        {
            var index = 0;
            for (int y = 0; y < weightMatrix.IntExtent.Y && index < weightData.Length; y++)
            {
                for (int x = 0; x < weightMatrix.IntExtent.X && index < weightData.Length; x++)
                {
                    weightMatrix.View[y, x] = weightData[index++];
                }
            }
        }
        inputVector?.View.CopyFromCPU(vectorData);
    }

    [Benchmark(Baseline = true)]
    public float StandardMatrixMultiplication()
    {
        var kernel = accelerator!.LoadAutoGroupedStreamKernel<
            Index2D, ArrayView2D<float, Stride2D.DenseX>, ArrayView2D<float, Stride2D.DenseX>, 
            ArrayView2D<float, Stride2D.DenseX>, int>(StandardMatMulKernel);

        if (inputMatrix == null || weightMatrix == null || outputMatrix == null)
        {
            return 0.0f;
        }

        kernel(new Index2D(MatrixSize, MatrixSize), inputMatrix.View, weightMatrix.View, outputMatrix.View, MatrixSize);
        accelerator!.Synchronize();
        
        var result = outputMatrix.GetAsArray2D();
        return result[0, 0];
    }

    [Benchmark]
    public float ANERealHardware()
    {
        if (!hasRealANE || aneAccelerator == null)
        {
            // Fall back to simulation when real ANE not available
            return ANESimulatedMatrixMultiplication();
        }

        try
        {
            // Use real Apple Neural Engine hardware
            var kernel = aneAccelerator.LoadAutoGroupedStreamKernel<
                Index2D, ArrayView2D<float, Stride2D.DenseX>, ArrayView2D<float, Stride2D.DenseX>, 
                ArrayView2D<float, Stride2D.DenseX>, int>(ANEHardwareKernel);

            if (inputMatrix == null || weightMatrix == null || outputMatrix == null)
            {
                return 0.0f;
            }

            kernel(new Index2D(MatrixSize, MatrixSize), inputMatrix.View, weightMatrix.View, outputMatrix.View, MatrixSize);
            aneAccelerator.Synchronize();
            
            var result = outputMatrix.GetAsArray2D();
            Console.WriteLine("üöÄ Executed on real Apple Neural Engine hardware");
            return result[0, 0];
        }
        catch (Exception ex)
        {
            Console.WriteLine($"‚ùå Real ANE execution failed: {ex.Message}");
            // Fall back to simulation
            return ANESimulatedMatrixMultiplication();
        }
    }

    [Benchmark]
    public float ANESimulatedMatrixMultiplication()
    {
        // Simulate ANE-optimized matrix multiplication with FP16 precision
        var kernel = accelerator!.LoadAutoGroupedStreamKernel<
            Index2D, ArrayView2D<float, Stride2D.DenseX>, ArrayView2D<float, Stride2D.DenseX>, 
            ArrayView2D<float, Stride2D.DenseX>, int>(ANEMatMulKernel);

        if (inputMatrix == null || weightMatrix == null || outputMatrix == null)
        {
            return 0.0f;
        }

        kernel(new Index2D(MatrixSize, MatrixSize), inputMatrix.View, weightMatrix.View, outputMatrix.View, MatrixSize);
        accelerator!.Synchronize();
        
        var result = outputMatrix.GetAsArray2D();
        return result[0, 0];
    }

    [Benchmark]
    public float ANEConvolution2D()
    {
        // Simulate ANE-optimized 2D convolution
        var kernel = accelerator!.LoadAutoGroupedStreamKernel<
            Index2D, ArrayView2D<float, Stride2D.DenseX>, ArrayView2D<float, Stride2D.DenseX>, 
            ArrayView2D<float, Stride2D.DenseX>, int, int>(ANEConvolutionKernel);

        if (inputMatrix == null || weightMatrix == null || outputMatrix == null)
        {
            return 0.0f;
        }

        var kernelSize = 3;
        kernel(new Index2D(MatrixSize - kernelSize + 1, MatrixSize - kernelSize + 1), 
               inputMatrix.View, weightMatrix.View, outputMatrix.View, MatrixSize, kernelSize);
        accelerator!.Synchronize();
        
        var result = outputMatrix.GetAsArray2D();
        return result[0, 0];
    }

    [Benchmark]
    public float ANEFullyConnectedLayer()
    {
        // Simulate ANE-optimized fully connected layer
        var kernel = accelerator!.LoadAutoGroupedStreamKernel<
            Index1D, ArrayView<float>, ArrayView2D<float, Stride2D.DenseX>, ArrayView<float>, int, int>(
            ANEFullyConnectedKernel);

        if (inputVector == null || weightMatrix == null || outputVector == null)
        {
            return 0.0f;
        }

        var inputSize = MatrixSize;
        var outputSize = MatrixSize / 2;
        
        kernel(outputSize * BatchSize, inputVector.View, weightMatrix.View, outputVector.View, inputSize, outputSize);
        accelerator!.Synchronize();
        
        var result = new float[1];
        outputVector.View.SubView(0, 1).CopyToCPU(result);
        return result[0];
    }

    [Benchmark]
    public float ANEBatchedInference()
    {
        // Simulate ANE-optimized batched inference pipeline
        var kernel = accelerator!.LoadAutoGroupedStreamKernel<
            Index2D, ArrayView<float>, ArrayView2D<float, Stride2D.DenseX>, ArrayView<float>, int, int, int>(
            ANEBatchedInferenceKernel);

        if (inputVector == null || weightMatrix == null || outputVector == null)
        {
            return 0.0f;
        }

        var hiddenSize = MatrixSize / 4;
        kernel(new Index2D(BatchSize, hiddenSize), inputVector.View, weightMatrix.View, outputVector.View, 
               MatrixSize, hiddenSize, BatchSize);
        accelerator!.Synchronize();
        
        var result = new float[1];
        outputVector.View.SubView(0, 1).CopyToCPU(result);
        return result[0];
    }

    [Benchmark]
    public float ANEActivationFunctions()
    {
        // Simulate ANE-optimized activation functions
        var kernel = accelerator!.LoadAutoGroupedStreamKernel<
            Index1D, ArrayView<float>, ArrayView<float>>(ANEActivationKernel);

        if (inputVector == null || outputVector == null)
        {
            return 0.0f;
        }

        kernel(MatrixSize * BatchSize, inputVector.View, outputVector.View);
        accelerator!.Synchronize();
        
        var result = new float[1];
        outputVector.View.SubView(0, 1).CopyToCPU(result);
        return result[0];
    }

    [Benchmark]
    public float ANEOptimizedDataFlow()
    {
        // Simulate ANE-optimized data flow with minimal memory transfers
        var kernel = accelerator!.LoadAutoGroupedStreamKernel<
            Index1D, ArrayView<float>, ArrayView<float>, int>(ANEDataFlowKernel);

        if (inputVector == null || outputVector == null)
        {
            return 0.0f;
        }

        kernel(MatrixSize, inputVector.View, outputVector.View, BatchSize);
        accelerator!.Synchronize();
        
        var result = new float[1];
        outputVector.View.SubView(0, 1).CopyToCPU(result);
        return result[0];
    }

    #region ANE Kernels

    private static void ANEHardwareKernel(
        Index2D index,
        ArrayView2D<float, Stride2D.DenseX> a,
        ArrayView2D<float, Stride2D.DenseX> b,
        ArrayView2D<float, Stride2D.DenseX> c,
        int size)
    {
        if (index.X >= size || index.Y >= size)
        {
            return;
        }

        // This kernel will be executed on real ANE hardware via ILGPU
        // The ANE accelerator will automatically optimize neural operations
        float sum = 0.0f;
        for (int k = 0; k < size; k++)
        {
            sum += a[index.X, k] * b[k, index.Y];
        }
        c[index.X, index.Y] = sum;
    }

    private static void StandardMatMulKernel(
        Index2D index,
        ArrayView2D<float, Stride2D.DenseX> a,
        ArrayView2D<float, Stride2D.DenseX> b,
        ArrayView2D<float, Stride2D.DenseX> c,
        int size)
    {
        if (index.X >= size || index.Y >= size)
        {
            return;
        }

        float sum = 0.0f;
        for (int k = 0; k < size; k++)
        {
            sum += a[index.X, k] * b[k, index.Y];
        }
        c[index.X, index.Y] = sum;
    }

    private static void ANEMatMulKernel(
        Index2D index,
        ArrayView2D<float, Stride2D.DenseX> a,
        ArrayView2D<float, Stride2D.DenseX> b,
        ArrayView2D<float, Stride2D.DenseX> c,
        int size)
    {
        if (index.X >= size || index.Y >= size)
        {
            return;
        }

        // Simulate ANE FP16 precision and optimized computation
        float sum = 0.0f;
        for (int k = 0; k < size; k++)
        {
            // Simulate FP16 precision by converting to Half and back
            var aVal = (float)(Half)a[index.X, k];
            var bVal = (float)(Half)b[k, index.Y];
            sum += aVal * bVal;
        }
        
        // ANE-style saturation
        c[index.X, index.Y] = IntrinsicMath.Min(65504.0f, IntrinsicMath.Max(-65504.0f, sum));
    }

    private static void ANEConvolutionKernel(
        Index2D index,
        ArrayView2D<float, Stride2D.DenseX> input,
        ArrayView2D<float, Stride2D.DenseX> kernel,
        ArrayView2D<float, Stride2D.DenseX> output,
        int inputSize,
        int kernelSize)
    {
        var outputSize = inputSize - kernelSize + 1;
        if (index.X >= outputSize || index.Y >= outputSize)
        {
            return;
        }

        float sum = 0.0f;
        for (int ky = 0; ky < kernelSize; ky++)
        {
            for (int kx = 0; kx < kernelSize; kx++)
            {
                var inputY = index.Y + ky;
                var inputX = index.X + kx;
                
                if (inputY < inputSize && inputX < inputSize)
                {
                    // Simulate ANE FP16 precision
                    var inputVal = (float)(Half)input[inputY, inputX];
                    var kernelVal = (float)(Half)kernel[ky, kx];
                    sum += inputVal * kernelVal;
                }
            }
        }
        
        // ANE-style ReLU activation
        output[index.Y, index.X] = IntrinsicMath.Max(0.0f, sum);
    }

    private static void ANEFullyConnectedKernel(
        Index1D index,
        ArrayView<float> input,
        ArrayView2D<float, Stride2D.DenseX> weights,
        ArrayView<float> output,
        int inputSize,
        int outputSize)
    {
        if (index >= output.Length)
        {
            return;
        }

        var outputIdx = index % outputSize;
        var batchIdx = index / outputSize;
        var inputOffset = batchIdx * inputSize;
        
        float sum = 0.0f;
        for (int i = 0; i < inputSize && (inputOffset + i) < input.Length; i++)
        {
            if (outputIdx < weights.IntExtent.Y && i < weights.IntExtent.X)
            {
                // Simulate ANE optimized computation
                var inputVal = (float)(Half)input[inputOffset + i];
                var weightVal = (float)(Half)weights[outputIdx, i];
                sum += inputVal * weightVal;
            }
        }
        
        // ANE-style activation with saturation
        output[index] = IntrinsicMath.Min(65504.0f, IntrinsicMath.Max(0.0f, sum));
    }

    private static void ANEBatchedInferenceKernel(
        Index2D index,
        ArrayView<float> input,
        ArrayView2D<float, Stride2D.DenseX> weights,
        ArrayView<float> output,
        int inputSize,
        int hiddenSize,
        int batchSize)
    {
        var batch = index.X;
        var hidden = index.Y;
        
        if (batch >= batchSize || hidden >= hiddenSize)
        {
            return;
        }

        var inputOffset = batch * inputSize;
        var outputIdx = batch * hiddenSize + hidden;
        
        if (outputIdx >= output.Length)
        {
            return;
        }

        // Simulate multi-layer perceptron with ANE optimizations
        float sum1 = 0.0f;
        for (int i = 0; i < inputSize && (inputOffset + i) < input.Length && i < weights.IntExtent.X; i++)
        {
            var inputVal = (float)(Half)input[inputOffset + i];
            var weightVal = (float)(Half)weights[hidden, i];
            sum1 += inputVal * weightVal;
        }
        
        // First layer with ReLU
        var hidden1 = IntrinsicMath.Max(0.0f, sum1);
        
        // Second layer computation (simplified)
        var finalOutput = hidden1 * 0.1f; // Simulate second layer weights
        
        output[outputIdx] = IntrinsicMath.Min(65504.0f, IntrinsicMath.Max(-65504.0f, finalOutput));
    }

    private static void ANEActivationKernel(
        Index1D index,
        ArrayView<float> input,
        ArrayView<float> output)
    {
        if (index >= input.Length || index >= output.Length)
        {
            return;
        }

        var value = input[index];
        
        // ANE-optimized activation functions with proper implementations
        // Convert to FP16 for ANE precision simulation
        var fp16Value = (float)(Half)value;
        
        // ReLU activation
        var relu = IntrinsicMath.Max(0.0f, fp16Value);
        
        // Swish activation: x * sigmoid(x) with accurate sigmoid implementation
        var sigmoidInput = IntrinsicMath.Clamp(fp16Value, -10.0f, 10.0f); // Prevent overflow
        var sigmoid = 1.0f / (1.0f + ExpApprox(-sigmoidInput));
        var swish = fp16Value * sigmoid;
        
        // GELU activation: 0.5 * x * (1 + tanh(sqrt(2/œÄ) * (x + 0.044715 * x¬≥)))
        var x3 = fp16Value * fp16Value * fp16Value;
        var gelu_inner = (float)Math.Sqrt(2.0 / Math.PI) * (fp16Value + 0.044715f * x3);
        var gelu = 0.5f * fp16Value * (1.0f + TanhApprox(gelu_inner));
        
        // ANE supports dynamic activation blending based on operation type
        // Use a more sophisticated blend that respects the mathematical properties
        var activationType = (int)(index * 1103515245) % 3; // Pseudo-random selection per element
        
        float result = activationType switch
        {
            0 => relu,
            1 => swish, 
            2 => gelu,
            _ => relu // Default fallback
        };
        
        // Apply ANE saturation limits (FP16 range)
        output[index] = IntrinsicMath.Min(65504.0f, IntrinsicMath.Max(-65504.0f, result));
    }

    private static void ANEDataFlowKernel(
        Index1D index,
        ArrayView<float> input,
        ArrayView<float> output,
        int batchSize)
    {
        if (index >= output.Length / batchSize)
        {
            return;
        }

        // Simulate ANE's optimized data flow with minimal memory access
        for (int batch = 0; batch < batchSize; batch++)
        {
            var inputIdx = batch * output.Length / batchSize + index;
            var outputIdx = batch * output.Length / batchSize + index;
            
            if (inputIdx < input.Length && outputIdx < output.Length)
            {
                // Simulate ANE's efficient data processing
                var value = (float)(Half)input[inputIdx];
                
                // Complex computation that benefits from ANE's architecture
                var processed = value;
                for (int iter = 0; iter < 3; iter++)
                {
                    processed = SinApprox(processed) * CosApprox(processed * 0.5f);
                    processed = IntrinsicMath.Max(-1.0f, IntrinsicMath.Min(1.0f, processed));
                }
                
                output[outputIdx] = processed;
            }
        }
    }

    #endregion

    #region Helper Methods

    private static double NextGaussian(Random random, double mean = 0, double stdDev = 1)
    {
        // Box-Muller transform for Gaussian distribution
        var u1 = 1.0 - random.NextDouble();
        var u2 = 1.0 - random.NextDouble();
        var randStdNormal = Math.Sqrt(-2.0 * Math.Log(u1)) * Math.Sin(2.0 * Math.PI * u2);
        return mean + stdDev * randStdNormal;
    }

    // GPU-compatible math approximations
    private static float SinApprox(float x)
    {
        // Fast sine approximation using Taylor series (first few terms)
        // sin(x) ‚âà x - x¬≥/6 + x‚Åµ/120 (for small x)
        // Normalize x to [-œÄ, œÄ] range first
        x = x - ((int)(x / (2.0f * 3.14159f))) * (2.0f * 3.14159f);
        if (x > 3.14159f)
        {
            x -= 2.0f * 3.14159f;
        }

        if (x < -3.14159f)
        {
            x += 2.0f * 3.14159f;
        }

        var x2 = x * x;
        return x * (1.0f - x2 / 6.0f + x2 * x2 / 120.0f);
    }

    private static float CosApprox(float x)
    {
        // Fast cosine approximation using Taylor series
        // cos(x) ‚âà 1 - x¬≤/2 + x‚Å¥/24
        x = x - ((int)(x / (2.0f * 3.14159f))) * (2.0f * 3.14159f);
        if (x > 3.14159f)
        {
            x -= 2.0f * 3.14159f;
        }

        if (x < -3.14159f)
        {
            x += 2.0f * 3.14159f;
        }

        var x2 = x * x;
        return 1.0f - x2 / 2.0f + x2 * x2 / 24.0f;
    }

    private static float ExpApprox(float x)
    {
        // Fast exponential approximation
        // e^x ‚âà 1 + x + x¬≤/2 + x¬≥/6 (Taylor series, limited terms)
        if (x > 10.0f)
        {
            return 22026.5f; // e^10 approximately
        }

        if (x < -10.0f)
        {
            return 0.0f;
        }

        var result = 1.0f + x;
        var term = x;
        term *= x / 2.0f;
        result += term;
        term *= x / 3.0f;
        result += term;
        return result;
    }

    private static float TanhApprox(float x)
    {
        // High-accuracy tanh approximation using rational function
        // Based on: tanh(x) = (e^x - e^-x) / (e^x + e^-x)
        if (x > 5.0f)
        {
            return 1.0f;
        }

        if (x < -5.0f)
        {
            return -1.0f;
        }

        // For moderate values, use exponential form with approximation
        if (IntrinsicMath.Abs(x) > 1.0f)
        {
            var exp_pos = ExpApprox(x);
            var exp_neg = ExpApprox(-x);
            return (exp_pos - exp_neg) / (exp_pos + exp_neg);
        }
        else
        {
            // For small values, use Taylor series: tanh(x) ‚âà x - x¬≥/3 + 2x‚Åµ/15
            var x2 = x * x;
            var x3 = x2 * x;
            var x5 = x3 * x2;
            return x - x3 / 3.0f + 2.0f * x5 / 15.0f;
        }
    }

    #endregion

    [GlobalCleanup]
    public void Cleanup()
    {
        Dispose();
    }

    public void Dispose()
    {
        inputMatrix?.Dispose();
        weightMatrix?.Dispose();
        outputMatrix?.Dispose();
        inputVector?.Dispose();
        outputVector?.Dispose();
        aneAccelerator?.Dispose();
        accelerator?.Dispose();
        context?.Dispose();
    }
}