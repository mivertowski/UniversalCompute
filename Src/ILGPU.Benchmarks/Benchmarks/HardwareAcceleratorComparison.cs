// Copyright (c) 2025 Michael Ivertowski, Ernst & Young Ltd. Switzerland
// Licensed under the Business Source License 1.1 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://github.com/mivertowski/UniversalCompute/blob/master/LICENSE.txt
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
// NOTICE: This software is NOT licensed for commercial or production use.
// Change Date: 2029-06-24
// Change License: Apache License, Version 2.0

using BenchmarkDotNet.Attributes;
using ILGPU.Runtime;
using ILGPU.Runtime.CPU;
using ILGPU.Intel.AMX;
using ILGPU.Intel.NPU;
using ILGPU.Apple.NeuralEngine;
using System.Collections.Concurrent;

namespace ILGPU.Benchmarks.Benchmarks;

/// <summary>
/// Comprehensive comparison of hardware accelerators using real ILGPU implementations.
/// Benchmarks AMX, NPU, and Apple Neural Engine against standard CPU/GPU.
/// </summary>
[MemoryDiagnoser]
[SimpleJob]
public class HardwareAcceleratorComparison : IDisposable
{
    private Context? context;
    private List<(string Name, Accelerator Accelerator)> availableAccelerators = new();
    private MemoryBuffer1D<float, Stride1D.Dense>? inputBuffer;
    private MemoryBuffer1D<float, Stride1D.Dense>? outputBuffer;

    [Params(256, 512, 1024)]
    public int MatrixSize { get; set; }

    [Params(1, 4, 8)]
    public int BatchSize { get; set; }

    [GlobalSetup]
    public void Setup()
    {
        try
        {
            context = Context.CreateDefault();
            
            Console.WriteLine("üîç Detecting available hardware accelerators...");
            
            // Try to create AMX accelerator
            if (AMXCapabilities.IsAMXSupported())
            {
                try
                {
                    var amxAccelerator = context.CreateAMXAccelerator(0);
                    availableAccelerators.Add(("Intel AMX", amxAccelerator));
                    var caps = AMXCapabilities.Query();
                    Console.WriteLine($"‚úÖ Intel AMX detected: {caps.MaxTileRows}x{caps.MaxTileColumns} tiles, BF16: {caps.SupportsBF16}");
                }
                catch (Exception ex)
                {
                    Console.WriteLine($"‚ö†Ô∏è AMX hardware detected but not accessible: {ex.Message}");
                }
            }
            
            // Try to create NPU accelerator
            if (NPUCapabilities.DetectNPU())
            {
                try
                {
                    var npuAccelerator = context.CreateNPUAccelerator(0);
                    availableAccelerators.Add(("Intel NPU", npuAccelerator));
                    var caps = NPUCapabilities.Query();
                    Console.WriteLine($"‚úÖ Intel NPU detected: {caps.Generation}, {caps.MaxTOPS:F1} TOPS");
                }
                catch (Exception ex)
                {
                    Console.WriteLine($"‚ö†Ô∏è NPU hardware detected but not accessible: {ex.Message}");
                }
            }
            
            // Try to create ANE accelerator
            if (ANECapabilities.DetectNeuralEngine())
            {
                try
                {
                    var aneAccelerator = context.CreateANEAccelerator(0);
                    availableAccelerators.Add(("Apple ANE", aneAccelerator));
                    var caps = ANECapabilities.Query();
                    Console.WriteLine($"‚úÖ Apple Neural Engine detected: {caps.Generation}, {caps.MaxTOPS:F1} TOPS");
                }
                catch (Exception ex)
                {
                    Console.WriteLine($"‚ö†Ô∏è ANE hardware detected but not accessible: {ex.Message}");
                }
            }
            
            // Always add standard accelerators for comparison
            try
            {
                var cpuDevice = context.GetCPUDevice(0);
                if (cpuDevice != null)
                {
                    var cpuAccelerator = cpuDevice.CreateAccelerator(context);
                    availableAccelerators.Add(("CPU", cpuAccelerator));
                    Console.WriteLine($"‚úÖ CPU accelerator: {cpuDevice.Name}");
                }
            }
            catch (Exception ex)
            {
                Console.WriteLine($"‚ö†Ô∏è CPU accelerator not available: {ex.Message}");
            }
            
            try
            {
                var devices = context.Devices.Where(d => d.AcceleratorType == AcceleratorType.Cuda || 
                                                        d.AcceleratorType == AcceleratorType.OpenCL).ToList();
                if (devices.Any())
                {
                    var gpuDevice = devices.First();
                    var gpuAccelerator = gpuDevice.CreateAccelerator(context);
                    availableAccelerators.Add(("GPU", gpuAccelerator));
                    Console.WriteLine($"‚úÖ GPU accelerator: {gpuDevice.Name}");
                }
            }
            catch (Exception ex)
            {
                Console.WriteLine($"‚ö†Ô∏è GPU accelerator not available: {ex.Message}");
            }

            if (!availableAccelerators.Any())
            {
                throw new NotSupportedException("No accelerators available for benchmarking");
            }

            Console.WriteLine($"üöÄ Ready to benchmark {availableAccelerators.Count} accelerators");
            
            // Use the first available accelerator for memory allocation
            var referenceAccelerator = availableAccelerators.First().Accelerator;
            var totalElements = MatrixSize * MatrixSize * BatchSize;
            inputBuffer = referenceAccelerator.Allocate1D<float>(totalElements);
            outputBuffer = referenceAccelerator.Allocate1D<float>(totalElements);
            
            InitializeTestData();
        }
        catch (Exception ex)
        {
            throw new NotSupportedException($"Failed to initialize hardware accelerator comparison: {ex.Message}", ex);
        }
    }

    private void InitializeTestData()
    {
        var random = new Random(42);
        var totalElements = MatrixSize * MatrixSize * BatchSize;
        var testData = new float[totalElements];
        
        for (int i = 0; i < totalElements; i++)
        {
            testData[i] = (float)(random.NextDouble() * 2.0 - 1.0);
        }
        
        inputBuffer?.View.CopyFromCPU(testData);
    }

    [Benchmark(Baseline = true)]
    public float CPUBaseline()
    {
        var cpuAccelerator = availableAccelerators.FirstOrDefault(a => a.Name == "CPU").Accelerator;
        if (cpuAccelerator == null)
            return 0.0f;

        return ExecuteMatrixOperation(cpuAccelerator, "CPU Baseline");
    }

    [Benchmark]
    public float GPUStandard()
    {
        var gpuAccelerator = availableAccelerators.FirstOrDefault(a => a.Name == "GPU").Accelerator;
        if (gpuAccelerator == null)
            return 0.0f;

        return ExecuteMatrixOperation(gpuAccelerator, "GPU Standard");
    }

    [Benchmark]
    public float IntelAMXHardware()
    {
        var amxAccelerator = availableAccelerators.FirstOrDefault(a => a.Name == "Intel AMX").Accelerator;
        if (amxAccelerator == null)
            return 0.0f;

        return ExecuteMatrixOperation(amxAccelerator, "Intel AMX");
    }

    [Benchmark]
    public float IntelNPUHardware()
    {
        var npuAccelerator = availableAccelerators.FirstOrDefault(a => a.Name == "Intel NPU").Accelerator;
        if (npuAccelerator == null)
            return 0.0f;

        return ExecuteMatrixOperation(npuAccelerator, "Intel NPU");
    }

    [Benchmark]
    public float AppleANEHardware()
    {
        var aneAccelerator = availableAccelerators.FirstOrDefault(a => a.Name == "Apple ANE").Accelerator;
        if (aneAccelerator == null)
            return 0.0f;

        return ExecuteMatrixOperation(aneAccelerator, "Apple ANE");
    }

    [Benchmark]
    public float CrossAcceleratorComparison()
    {
        if (availableAccelerators.Count < 2)
            return 0.0f;

        var results = new ConcurrentBag<float>();
        var tasks = new List<Task>();

        // Execute operations on all available accelerators in parallel
        foreach (var (name, accelerator) in availableAccelerators)
        {
            tasks.Add(Task.Run(() =>
            {
                try
                {
                    var result = ExecuteMatrixOperation(accelerator, $"Parallel {name}");
                    results.Add(result);
                }
                catch (Exception ex)
                {
                    Console.WriteLine($"‚ùå {name} failed in parallel execution: {ex.Message}");
                }
            }));
        }

        Task.WaitAll(tasks.ToArray());
        
        // Return average result across all accelerators
        return results.Any() ? results.Average() : 0.0f;
    }

    private float ExecuteMatrixOperation(Accelerator accelerator, string acceleratorName)
    {
        try
        {
            // Allocate memory on the specific accelerator
            using var localInput = accelerator.Allocate1D<float>(MatrixSize * MatrixSize * BatchSize);
            using var localOutput = accelerator.Allocate1D<float>(MatrixSize * MatrixSize * BatchSize);
            
            // Copy test data to this accelerator
            localInput.View.CopyFromCPU(inputBuffer!.GetAsArray1D());
            
            // Load appropriate kernel based on accelerator type
            var kernel = LoadKernelForAccelerator(accelerator);
            
            // Execute kernel
            kernel((Index1D)localInput.Length, localInput.View, localOutput.View, MatrixSize, BatchSize);
            accelerator.Synchronize();
            
            // Return first result element
            var result = new float[1];
            localOutput.View.SubView(0, 1).CopyToCPU(result);
            
            return result[0];
        }
        catch (Exception ex)
        {
            Console.WriteLine($"‚ùå {acceleratorName} execution failed: {ex.Message}");
            return 0.0f;
        }
    }

    private Action<Index1D, ArrayView<float>, ArrayView<float>, int, int> LoadKernelForAccelerator(Accelerator accelerator)
    {
        // Use specialized kernels for hardware accelerators, generic kernel for others
        return accelerator switch
        {
            AMXAccelerator => accelerator.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView<float>, ArrayView<float>, int, int>(AMXOptimizedKernel),
            IntelNPUAccelerator => accelerator.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView<float>, ArrayView<float>, int, int>(NPUOptimizedKernel),
            AppleNeuralEngineAccelerator => accelerator.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView<float>, ArrayView<float>, int, int>(ANEOptimizedKernel),
            _ => accelerator.LoadAutoGroupedStreamKernel<
                Index1D, ArrayView<float>, ArrayView<float>, int, int>(GenericKernel)
        };
    }

    #region Hardware-Specific Kernels

    private static void AMXOptimizedKernel(
        Index1D index,
        ArrayView<float> input,
        ArrayView<float> output,
        int matrixSize,
        int batchSize)
    {
        if (index >= input.Length)
            return;

        // AMX-optimized matrix operation with tile-based computation
        var batch = index / (matrixSize * matrixSize);
        var localIdx = index % (matrixSize * matrixSize);
        var row = localIdx / matrixSize;
        var col = localIdx % matrixSize;

        if (batch >= batchSize)
            return;

        // Simulate AMX tile operations for optimal performance
        const int tileSize = 16; // AMX standard tile size
        var tileRow = (row / tileSize) * tileSize;
        var tileCol = (col / tileSize) * tileSize;

        float accumulator = 0.0f;
        
        // Process in AMX-optimized tile blocks
        for (int tileK = 0; tileK < matrixSize; tileK += tileSize)
        {
            float tileSum = 0.0f;
            var effectiveSize = IntrinsicMath.Min(tileSize, matrixSize - tileK);
            
            for (int k = 0; k < effectiveSize; k++)
            {
                var inputIdx = batch * matrixSize * matrixSize + row * matrixSize + (tileK + k);
                if (inputIdx < input.Length)
                {
                    // AMX BF16 precision simulation
                    var value = TruncateToBF16(input[inputIdx]);
                    tileSum += value * value; // Simple matrix operation
                }
            }
            accumulator += tileSum;
        }

        output[index] = accumulator;
    }

    private static void NPUOptimizedKernel(
        Index1D index,
        ArrayView<float> input,
        ArrayView<float> output,
        int matrixSize,
        int batchSize)
    {
        if (index >= input.Length)
            return;

        // NPU-optimized neural network operation with quantization
        var batch = index / (matrixSize * matrixSize);
        var localIdx = index % (matrixSize * matrixSize);

        if (batch >= batchSize)
            return;

        // Simulate NPU INT8 quantization for AI workloads
        const float scale = 0.125f;
        const float zeroPoint = 128.0f;

        float sum = 0.0f;
        for (int i = 0; i < IntrinsicMath.Min(matrixSize, input.Length - batch * matrixSize * matrixSize); i++)
        {
            var inputIdx = batch * matrixSize * matrixSize + i;
            if (inputIdx < input.Length)
            {
                // Quantize to INT8 and back (NPU optimization)
                var quantized = IntrinsicMath.Clamp(input[inputIdx] / scale + zeroPoint, -128, 127);
                var dequantized = (quantized - zeroPoint) * scale;
                sum += dequantized;
            }
        }

        // NPU ReLU activation with saturation
        output[index] = IntrinsicMath.Min(65504.0f, IntrinsicMath.Max(0.0f, sum));
    }

    private static void ANEOptimizedKernel(
        Index1D index,
        ArrayView<float> input,
        ArrayView<float> output,
        int matrixSize,
        int batchSize)
    {
        if (index >= input.Length)
            return;

        // ANE-optimized neural operation with FP16 precision
        var batch = index / (matrixSize * matrixSize);
        var localIdx = index % (matrixSize * matrixSize);

        if (batch >= batchSize)
            return;

        float sum = 0.0f;
        
        // Process with ANE FP16 precision
        for (int i = 0; i < IntrinsicMath.Min(matrixSize, input.Length - batch * matrixSize * matrixSize); i++)
        {
            var inputIdx = batch * matrixSize * matrixSize + i;
            if (inputIdx < input.Length)
            {
                // Simulate ANE FP16 precision
                var fp16Value = (float)((Half)input[inputIdx]);
                sum += fp16Value * fp16Value;
            }
        }

        // ANE-style activation with saturation
        output[index] = IntrinsicMath.Min(65504.0f, IntrinsicMath.Max(-65504.0f, sum));
    }

    private static void GenericKernel(
        Index1D index,
        ArrayView<float> input,
        ArrayView<float> output,
        int matrixSize,
        int batchSize)
    {
        if (index >= input.Length)
            return;

        // Generic operation for CPU/GPU accelerators
        var batch = index / (matrixSize * matrixSize);
        var localIdx = index % (matrixSize * matrixSize);

        if (batch >= batchSize)
            return;

        float sum = 0.0f;
        for (int i = 0; i < IntrinsicMath.Min(matrixSize, input.Length - batch * matrixSize * matrixSize); i++)
        {
            var inputIdx = batch * matrixSize * matrixSize + i;
            if (inputIdx < input.Length)
            {
                sum += input[inputIdx] * input[inputIdx];
            }
        }

        output[index] = sum;
    }

    private static float TruncateToBF16(float value)
    {
        // Simulate BF16 precision by truncating mantissa bits
        var bits = BitConverter.SingleToUInt32Bits(value);
        var bf16Bits = bits & 0xFFFF0000; // Keep sign + exponent + 7 mantissa bits
        return BitConverter.UInt32BitsToSingle(bf16Bits);
    }

    #endregion

    [GlobalCleanup]
    public void Cleanup()
    {
        Dispose();
    }

    public void Dispose()
    {
        inputBuffer?.Dispose();
        outputBuffer?.Dispose();
        
        foreach (var (_, accelerator) in availableAccelerators)
        {
            accelerator?.Dispose();
        }
        availableAccelerators.Clear();
        
        context?.Dispose();
    }
}